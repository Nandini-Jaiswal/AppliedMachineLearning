{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up `DVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "#Initialize a new dvc init project in the parnet directory of the current working directory\n",
    "%cd ..\n",
    "!dvc init\n",
    "%cd Assignment_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sms_data(file_path='SMSSpamCollection'):\n",
    "    \"\"\"\n",
    "    Read SMS data from a file and return a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the SMS data file (default: 'SMSSpamCollection')\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the SMS data with 'label' and 'text' columns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, delimiter='\\t', header=None, names=['label', 'text'])\n",
    "        print(f\"Successfully read {len(df)} messages\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 5572 messages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_sms_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define `utility functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, output_file):\n",
    "    \"\"\"\n",
    "    Save the raw SMS data to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame containing the SMS data\n",
    "        output_file (str): Name of the output CSV file (default: 'raw_data.csv')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully saved {len(data)} messages to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "def compare_ham_spam(train_data, validation_data, test_data):\n",
    "    \"\"\"\n",
    "    Compare the total number of hams and spams in train, validation, and test datasets.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pandas.DataFrame): Training dataset\n",
    "        validation_data (pandas.DataFrame): Validation dataset\n",
    "        test_data (pandas.DataFrame): Test dataset\n",
    "        \n",
    "    Returns:\n",
    "        PrettyTable: Table comparing the number of hams and spams in each dataset\n",
    "    \"\"\"\n",
    "    # Count hams and spams in each dataset\n",
    "    train_counts = train_data['label'].value_counts()\n",
    "    validation_counts = validation_data['label'].value_counts()\n",
    "    test_counts = test_data['label'].value_counts()\n",
    "    \n",
    "    # Create a PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Dataset\", \"Ham\", \"Spam\"]\n",
    "    \n",
    "    # Add rows to the table\n",
    "    table.add_row([\"Train\", train_counts.get('ham', 0), train_counts.get('spam', 0)])\n",
    "    table.add_row([\"Validation\", validation_counts.get('ham', 0), validation_counts.get('spam', 0)])\n",
    "    table.add_row([\"Test\", test_counts.get('ham', 0), test_counts.get('spam', 0)])\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the raw data to `raw_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 5572 messages to raw_data.csv\n"
     ]
    }
   ],
   "source": [
    "save_data(df, \"raw_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to perform `train/test/val` split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_data(data, random_seed):\n",
    "    \"\"\"\n",
    "    Split data into train, validation and test sets and save them as CSV files.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to the raw data CSV file\n",
    "        random_seed (int): Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Read the data\n",
    "    df = data\n",
    "    \n",
    "    # First split: 80% train+val, 20% test\n",
    "    train_val, test = train_test_split(df, test_size=0.3, \n",
    "                                     random_state=random_seed)\n",
    "    \n",
    "    # Second split: 80% train, 20% validation (from train_val)\n",
    "    train, val = train_test_split(train_val, test_size=0.2, \n",
    "                                 random_state=random_seed)\n",
    "    \n",
    "    # Save the splits\n",
    "    train.to_csv('train.csv', index=False)\n",
    "    val.to_csv('validation.csv', index=False)\n",
    "    test.to_csv('test.csv', index=False)\n",
    "    \n",
    "    print(f\"Train size: {len(train)}\")\n",
    "    print(f\"Validation size: {len(val)}\")\n",
    "    print(f\"Test size: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the `Version 0` of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3565\n",
      "Validation size: 892\n",
      "Test size: 1115\n"
     ]
    }
   ],
   "source": [
    "split_and_save_data(df, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding DVC (Data Version Control)\n",
    "\n",
    "DVC (Data Version Control) is an open-source tool designed for data science and machine learning projects that enables versioning of large files.\n",
    "\n",
    "#### How DVC Works\n",
    "\n",
    "1. **Git Integration**: DVC extends Git's functionality by storing data file metadata in Git while the actual data is stored in remote storage.\n",
    "\n",
    "2. **Storage Management**: Instead of storing large datasets in Git (which can be inefficient), DVC stores references to the data in Git and the actual data in configurable remote storage (like Google Drive, S3, etc.).\n",
    "\n",
    "3. **File Tracking**: DVC replaces large files with small metafiles that are tracked by Git. These metafiles contain information needed to uniquely identify and reproduce the data.\n",
    "\n",
    "#### Important DVC Commands\n",
    "\n",
    "- `dvc init`: Initialize a DVC project in a Git repository\n",
    "- `dvc add <file>`: Start tracking a file with DVC\n",
    "- `dvc remote add`: Configure a remote storage location\n",
    "- `dvc push`: Upload tracked data to remote storage\n",
    "- `dvc pull`: Download data from remote storage\n",
    "- `dvc checkout`: Update working directory with tracked files\n",
    "- `dvc commit`: Record changes to tracked files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up remote storage\n",
    "The following code writes a `.config` file that stores the required credentials to push the data files to google drive.\n",
    "\n",
    "The encrypted files can be accessed [here](https://drive.google.com/drive/folders/10XuqI_krQMY_ZOFGlwqgMUDOX2Xg789O?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'gdrive' as a default remote.\n"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d gdrive gdrive://10XuqI_krQMY_ZOFGlwqgMUDOX2Xg789O\n",
    "!dvc remote modify gdrive_remote gdrive_client_id \"<cliet_id>\"\n",
    "!dvc remote modify gdrive_remote gdrive_client_secret \"<client_secret>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding large data files to `dvc`.\n",
    "\n",
    "Note that, we are adding the newly generated `.dvc` files to `Git`, not the actual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add test.csv.dvc validation.csv.dvc train.csv.dvc raw_data.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the CSV files to DVC tracking\n",
    "!dvc add raw_data.csv train.csv validation.csv test.csv\n",
    "\n",
    "# Add and commit changes to git\n",
    "!git add raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tnew file:   raw_data.csv.dvc\n",
      "\tnew file:   test.csv.dvc\n",
      "\tnew file:   train.csv.dvc\n",
      "\tnew file:   validation.csv.dvc\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\tprepare.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Committing the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main ca9936e] V0: Committing data files\n",
      " 4 files changed, 20 insertions(+)\n",
      " create mode 100644 Assignment_2/raw_data.csv.dvc\n",
      " create mode 100644 Assignment_2/test.csv.dvc\n",
      " create mode 100644 Assignment_2/train.csv.dvc\n",
      " create mode 100644 Assignment_2/validation.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc commit raw_data.csv train.csv validation.csv test.csv\n",
    "\n",
    "!git commit -m \"V0: Committing data files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pushing the data to remote storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=1046188398954-djkl9k2eb6dte6o11kt054hlv8tidlqq.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n",
      "\n",
      "Authentication successful.\n",
      "3 files pushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandini\\Documents\\CMI\\AppliedMachineLearning\\venv\\Lib\\site-packages\\oauth2client\\_helpers.py:255: UserWarning: Cannot access C:\\Users\\Nandini\\AppData\\Local\\pydrive2fs\\Cache\\1046188398954-djkl9k2eb6dte6o11kt054hlv8tidlqq.apps.googleusercontent.com\\default.json: No such file or directory\n",
      "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+\n",
      "|  Dataset   | Ham  | Spam |\n",
      "+------------+------+------+\n",
      "|   Train    | 3087 | 478  |\n",
      "| Validation | 772  | 120  |\n",
      "|    Test    | 966  | 149  |\n",
      "+------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "print(compare_ham_spam(train_data, validation_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up `version 1` of the data\n",
    "\n",
    "- follow the same steps as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3120\n",
      "Validation size: 780\n",
      "Test size: 1672\n"
     ]
    }
   ],
   "source": [
    "split_and_save_data(df, random_seed=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add train.csv.dvc validation.csv.dvc raw_data.csv.dvc test.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dvc add raw_data.csv train.csv validation.csv test.csv\n",
    "!git add raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 5a40bf0] V1: Committing data files\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!dvc commit raw_data.csv train.csv validation.csv test.csv\n",
    "!git commit -m \"V1: Committing data files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 files pushed\n"
     ]
    }
   ],
   "source": [
    "!dvc push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+\n",
      "|  Dataset   | Ham  | Spam |\n",
      "+------------+------+------+\n",
      "|   Train    | 2713 | 407  |\n",
      "| Validation | 674  | 106  |\n",
      "|    Test    | 1438 | 234  |\n",
      "+------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(compare_ham_spam(train_data, validation_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out `Version 0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show git commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a40bf0 V1: Committing data files\n",
      "ca9936e V0: Committing data files\n",
      "a4bb3dc Add `dvc` to the project\n",
      "284cb58 Modularizing the functions\n",
      "a54b433 Add `assignment 1`\n",
      "5937698 Add helper files\n",
      "d52a256 Initial commit\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkout the `V0` version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to 'ca9936e'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at ca9936e V0: Committing data files\n"
     ]
    }
   ],
   "source": [
    "!git checkout ca9936e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       train.csv\n",
      "M       test.csv\n",
      "M       validation.csv\n"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+\n",
      "|  Dataset   | Ham  | Spam |\n",
      "+------------+------+------+\n",
      "|   Train    | 3087 | 478  |\n",
      "| Validation | 772  | 120  |\n",
      "|    Test    | 966  | 149  |\n",
      "+------------+------+------+\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(compare_ham_spam(train_data, validation_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the table is same as the table for `V0` version.\n",
    "\n",
    "#### Checking out the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\trequirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD is now at 5a40bf0 V1: Committing data files\n"
     ]
    }
   ],
   "source": [
    "!git checkout 5a40bf0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
